{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842e7b61",
   "metadata": {},
   "source": [
    "#                PROJET MACHINE LEARNING LOQUET ANTOINE M2 OPHO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f64492",
   "metadata": {},
   "source": [
    "Importation des bibliothèques nécéssaires : \n",
    "Importing the necessary libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, validation_curve \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141329f",
   "metadata": {},
   "source": [
    "Importation du fichier : ( Mettre chemin d'accès du fichier roboBohr.csv) \n",
    "Import file: ( Set path to roboBohr.csv file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340ef3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chemin_fichier = 'Mettre chemin d accès'\n",
    "df = pd.read_csv(chemin_fichier)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a689ee",
   "metadata": {},
   "source": [
    "La commande df permet d'avoir un rapide apercu du DataFrame, il sera mieux analysé par la suite\n",
    "The df command gives you a quick overview of the DataFrame, which you can then analyze further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecfed3c",
   "metadata": {},
   "source": [
    "# 1 Analyse du DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2d64bc",
   "metadata": {},
   "source": [
    "## 1.1 Analyse de forme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fcc71",
   "metadata": {},
   "source": [
    "Analyse de la taille du DataFrame :\n",
    "DataFrame size analysis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad774ad",
   "metadata": {},
   "source": [
    "La taille du DataFrame est de 16 242 lignes et 1 278 colonnes\n",
    "DataFrame size is 16,242 rows and 1,278 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1661217",
   "metadata": {},
   "source": [
    "Analyse du nombre des différents types de colonnes : \n",
    "Analysis of the number of different column types : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2086611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920c948",
   "metadata": {},
   "source": [
    "Parmi les 1 278 colonnes, 2 sont de type int64 et le reste des float64. On voit ici que nous sommes dans un problème de type régression et de de classification\n",
    "Of the 1,278 columns, 2 are int64 and the rest float64. We can see here that we're dealing with a regression and classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837a42e",
   "metadata": {},
   "source": [
    "Analyse plus précise des colonnes de type int64\n",
    "More precise analysis of int64 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_int64 = df.select_dtypes(include='int64')\n",
    "print(colonnes_int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777761c",
   "metadata": {},
   "source": [
    "Les int64 ont pour nom Unnamed: 0 et pubchem_id, elles ne semblent pas intéréssantes pour la suite\n",
    "The int64s are Unnamed: 0 and pubchem_id, and don't seem to be of interest for the rest of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12b803",
   "metadata": {},
   "source": [
    "Vérification de la présence de NaN : \n",
    "Checking for the presence of NaN : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_de_nans = df.isna().sum().sum()\n",
    "print(nombre_de_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16878351",
   "metadata": {},
   "source": [
    "Il n'y a pas de NaN dans le DataFrame\n",
    "There is no NaN in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b633d",
   "metadata": {},
   "source": [
    "Calcul du nombre de cases nulles dans le DataFrame : \n",
    "Calculating the number of null cells in the DataFrame : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2218270",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_de_zero = (df==0.0 ).sum().sum()\n",
    "print(nombre_de_zero/(df.shape[0]*df.shape[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c52913",
   "metadata": {},
   "source": [
    "71 % des valeurs sont des 0 \n",
    "71% of values are 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47932224",
   "metadata": {},
   "source": [
    "## 1.2 Analyse de fond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['pubchem_id','Unnamed: 0', 'Eat'], axis=1)\n",
    "Y=df['Eat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ab12e",
   "metadata": {},
   "source": [
    "Séparation du DataFrame en deux, X pour les variables et Y pour les outputs. Les colonnes inutiles sont également retirées\n",
    "Separation of the DataFrame into X for variables and Y for outputs. Unnecessary columns are also removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9d1ed",
   "metadata": {},
   "source": [
    "Données statistiques de Y qui nous serviront pour la comparation finale des modèles \n",
    "Y statistical data for final model comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['Eat'],kde=True, color='blue')\n",
    "plt.title('Histogramme des valeurs')\n",
    "plt.xlabel('Valeurs')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a037bd2",
   "metadata": {},
   "source": [
    "Histogramme de Y, qui nous serivra aussi pour comparer les resultats des modèles \n",
    "Histogram of Y, which we can also use to compare model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f036deb",
   "metadata": {},
   "source": [
    "Standardisation de X :\n",
    "Standardizing X :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7321074",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand = pd.DataFrame(StandardScaler().fit_transform(X)) #moyenne nulle et un écart type de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a61fb",
   "metadata": {},
   "source": [
    "Normalisation de X : \n",
    "Normalization of X : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ffcc03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_stand_norm_l1=pd.DataFrame(normalize(X_stand, norm='l1', axis=0)) \n",
    "X_stand_norm_l2=pd.DataFrame(normalize(X_stand, norm='l2', axis=0)) \n",
    "X_stand_norm_max=pd.DataFrame(normalize(X_stand, norm='max', axis=0)) \n",
    "max_line_l1 = X_stand_norm_l1.describe().loc['mean']\n",
    "max_line_l2 = X_stand_norm_l2.describe().loc['mean']\n",
    "max_line_max = X_stand_norm_max.describe().loc['mean']\n",
    "\n",
    "# Créer une nouvelle figure avec trois sous-graphiques\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Tracer la ligne maximale pour la norme L1\n",
    "axs[0].plot(max_line_l1.index, max_line_l1.values, marker='o', linestyle='-', color='red')\n",
    "axs[0].set_xlabel('Colonnes')\n",
    "axs[0].set_ylabel('Valeurs maximales')\n",
    "axs[0].set_title('Norme L1')\n",
    "\n",
    "# Tracer la ligne maximale pour la norme L2\n",
    "axs[1].plot(max_line_l2.index, max_line_l2.values, marker='o', linestyle='-', color='blue')\n",
    "axs[1].set_xlabel('Colonnes')\n",
    "axs[1].set_ylabel('Valeurs maximales')\n",
    "axs[1].set_title('Norme L2')\n",
    "\n",
    "# Tracer la ligne maximale pour la norme max\n",
    "axs[2].plot(max_line_max.index, max_line_max.values, marker='o', linestyle='-', color='green')\n",
    "axs[2].set_xlabel('Colonnes')\n",
    "axs[2].set_ylabel('Valeurs maximales')\n",
    "axs[2].set_title('Norme max')\n",
    "\n",
    "# Ajuster la disposition des sous-graphiques\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40777b40",
   "metadata": {},
   "source": [
    "J'ai constaté qu'il existait plusieurs normalisations, j'ai alors décidé de les comparer graphiquement. Je constate que la normalisation L1 donne une moyenne moins fluctuante, c'est pourquoi je l'ai choisie.\n",
    "\n",
    "I found that there were several normalizations, so I decided to compare them graphically. I found that the L1 normalization gave a less fluctuating average, which is why I chose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506fb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X_stand_norm_l1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cdba86",
   "metadata": {},
   "source": [
    "PCA Permet de reduire la taille de X à 15 colonnes (valeur déterminée ci dessous) au lieu de 1275 en gardant 99% des informations\n",
    "\n",
    "PCA Reduces the size of X to 15 columns (value determined below) instead of 1275, keeping 99% of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ed981",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=X_pca.join(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(new_df, test_size=0.2, random_state=0) \n",
    "#Séparation des données pour entrainer une partie et pour tester le modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b168d97",
   "metadata": {},
   "source": [
    "Séparation du DataFrame réduit en deux set, un train set et un test set pour nos modèles. La répartition des données est 20% pour le train set et 80% pour le test set. J'ai placé un random_state pour pouvoir comparer mes resultats malgré plusieurs relance\n",
    "\n",
    "Separation of the reduced DataFrame into two sets, a train set and a test set for our models. Data distribution is 20% for the train set and 80% for the test set. I've set a random_state so that I can compare my results despite several relaunches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_set.drop(['Eat'], axis=1)\n",
    "Y_train=train_set['Eat']\n",
    "X_test=test_set.drop(['Eat'], axis=1)\n",
    "Y_test=test_set['Eat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182205f6",
   "metadata": {},
   "source": [
    "Séparation des variables et des outputs pour les deux sets \n",
    "Separation of variables and outputs for both sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467853d",
   "metadata": {},
   "source": [
    "Analyse des colonnes du train set : \n",
    "Analysis of train set columns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22902c1a",
   "metadata": {},
   "source": [
    "L'histogramme est similaire à Y et les valeurs des colonnes sont centrées autour de 0, ce qui montre que la standisation et la normalisation sont conservées. \n",
    "\n",
    "The histogram is similar to Y, and the column values are centered around 0, showing that standardization and normalization are preserved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9344d7f5",
   "metadata": {},
   "source": [
    "# 2 Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7842e",
   "metadata": {},
   "source": [
    "## 2.1 Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcee10d",
   "metadata": {},
   "source": [
    "Création d'une fonction qui va permettre d'évaluer les modèles avant et sans optmisation des hyperparamètres : \n",
    "Creation of a function to evaluate models before and without optmization of hyperparameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_class, X_train, Y_train, X_test, Y_test, best_params=None):\n",
    "\n",
    "    # Vérifier si des paramètres optimaux sont fournis\n",
    "    if best_params is None:\n",
    "        # Créer une instance du modèle avec les paramètres par défaut\n",
    "        model = model_class()\n",
    "        # Entraîner le modèle sur les données d'entraînement\n",
    "        model_train = model.fit(X_train, Y_train)\n",
    "        # Calculer le score d'entraînement\n",
    "        train_score = model.score(X_train, Y_train)\n",
    "        # Calculer le score de test\n",
    "        test_score = model.score(X_test, Y_test)\n",
    "        \n",
    "        # Afficher les scores et l'écart entre le score d'entraînement et de test\n",
    "        print(\"Score d'entraînement : \", train_score, '\\n'\n",
    "              \"Score de test : \", test_score, '\\n'\n",
    "              \"Écart : \", train_score - test_score)\n",
    "\n",
    "        # Vérifier s'il y a un surajustement (overfitting)\n",
    "        if train_score < test_score:\n",
    "            print(\"Surajustement, paramètres à ajuster\")\n",
    "        \n",
    "        # Renvoyer le modèle entraîné et les scores\n",
    "        return model_train, train_score, test_score\n",
    "    else:\n",
    "        # Créer une instance du modèle avec les meilleurs paramètres fournis\n",
    "        best_model = model_class(**best_params)\n",
    "        # Entraîner le modèle sur les données d'entraînement\n",
    "        best_model_train = best_model.fit(X_train, Y_train)\n",
    "        # Calculer le score d'entraînement\n",
    "        best_train_score = best_model.score(X_train, Y_train)\n",
    "        # Calculer le score de test\n",
    "        best_test_score = best_model.score(X_test, Y_test)\n",
    "        \n",
    "        # Afficher les scores et l'écart entre le score d'entraînement et de test\n",
    "        print(\"Score d'entraînement : \", best_train_score, '\\n'\n",
    "              \"Score de test : \", best_test_score, '\\n'\n",
    "              \"Écart : \", best_train_score - best_test_score)\n",
    "        \n",
    "        # Vérifier s'il y a un surajustement (overfitting)\n",
    "        if best_train_score < best_test_score:\n",
    "            print(\"Surajustement, paramètres à ajuster\")\n",
    "            \n",
    "        # Renvoyer le modèle entraîné avec les meilleurs paramètres et les scores\n",
    "        return best_model_train, best_train_score, best_test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b69f9",
   "metadata": {},
   "source": [
    " Création d'une fonction qui trouve les meilleurs hyperparamètres pour un modèle en utilisant la recherche sur grille : \n",
    " Create a function that finds the best hyperparameters for a model using grid search : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_param(model, X_train, Y_train, param_grid):\n",
    "\n",
    "    # Créer une instance de GridSearchCV avec le modèle, la grille d'hyperparamètres, la validation croisée et la métrique de performance\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    # Effectuer la recherche sur grille sur les données d'entraînement\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    # Obtenir les meilleurs hyperparamètres trouvés par la recherche sur grille\n",
    "    best_params = grid_search.best_params_\n",
    "    # Afficher les meilleurs hyperparamètres\n",
    "    print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "    \n",
    "    # Renvoyer les meilleurs hyperparamètres\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cb8eb",
   "metadata": {},
   "source": [
    "Création d'une fonction qui vérifie si l'ajustement a fonctionné ou non :\n",
    "Create a function that checks whether the adjustment has worked or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afb828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Verification_opti(best_train, best_test, train, test):\n",
    "\n",
    "    # Vérifier si le score sur l'ensemble d'entraînement est optimisé\n",
    "    if best_train > train:\n",
    "        print('Le set train est optimisé')\n",
    "    else:\n",
    "        print('Le set train n\\'est pas optimisé')\n",
    "\n",
    "    # Vérifier si le score sur l'ensemble de test est optimisé\n",
    "    if best_test > test:\n",
    "        print('Le set test est optimisé')\n",
    "    else:\n",
    "        print('Le set test n\\'est pas optimisé')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8fd7f5",
   "metadata": {},
   "source": [
    "Création d'une fonction qui vérifie la robustesse du modèle avec la validation croisée : \n",
    "Creation of a function that checks the robustness of the model with cross-validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustesse(modele):\n",
    "    num_folds = 7\n",
    "\n",
    "    # Créer un objet KFold pour spécifier la stratégie de validation croisée\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Utiliser cross_val_score pour obtenir les scores de chaque fold avec R2 score comme métrique\n",
    "    r2_scorer = make_scorer(r2_score)  # Créer un objet scorer pour R2 score\n",
    "    scores_r2 = cross_val_score(modele, X_train, Y_train, scoring=r2_scorer, cv=kf)\n",
    "\n",
    "    # Afficher les scores R2 pour chaque fold\n",
    "    print('Scores R2 pour chaque fold :', scores_r2)\n",
    "\n",
    "    # Calculer la moyenne des scores R2\n",
    "    average_r2 = np.mean(scores_r2)\n",
    "\n",
    "    print(f'Moyenne R2 sur {num_folds} folds : {average_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688eae53",
   "metadata": {},
   "source": [
    "## 2.2 Modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf49b2",
   "metadata": {},
   "source": [
    "### 2.2.1 LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2a7c30",
   "metadata": {},
   "source": [
    "Evaluation du modèle LinearRegression : \n",
    "Evaluation of the LinearRegression model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cfade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_model, Reg_train_score, Reg_test_score = evaluation(LinearRegression, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab49b0",
   "metadata": {},
   "source": [
    "Pas d'overfitting, et un R2 score un peu juste. Vérifions avec la validation croisée, si le score reste identique ou non pour déterminer la robustesse du modèle (Je chercher seulement la robustesse de la meilleure version du modèle) : \n",
    "\n",
    "No overfitting, and an R2 score that's just right. Let's check with cross-validation whether the score remains the same or not to determine the robustness of the model (I'm only looking for the robustness of the best version of the model): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(Reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d025a16",
   "metadata": {},
   "source": [
    "Le modèle est robuste dans son ensemble. Il peut être nécessaire d'explorer d'autres approches de modélisation, d'ajuster les hyperparamètres, ou de considérer des caractéristiques supplémentaires pour améliorer davantage les performances du modèle. La grille ci dessous, va essayer d'améliorer le score : \n",
    "\n",
    "The model is robust overall. It may be necessary to explore other modeling approaches, adjust hyperparameters, or consider additional features to further improve model performance. The grid below will attempt to improve the score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_reg = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c7c22",
   "metadata": {},
   "source": [
    "La grille étant définit, il faut chercher la meilleure combinaison qui donnera l'erreur quadratique moyenne négative la plus faible : \n",
    "Now that the grid has been defined, we need to look for the best combination that will give the lowest negative root mean square error: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7df99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_param_reg = best_param(Reg_model, X_train, Y_train, param_grid_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b8807",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'fit_intercept': True, 'positive': False}. Nouvelle évaluation avec ces nouveaux paramètres :\n",
    "\n",
    "The best hyperparameters are: {'fit_intercept': True, 'positive': False}. New evaluation with these new parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_model, best_reg_train_score, best_reg_test_score = evaluation(LinearRegression, X_train, Y_train, X_test, Y_test, best_param_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3921e9",
   "metadata": {},
   "source": [
    "Pas d'overfitting, et un R2 score toujours un peu juste. Vérification des l'optimisation :\n",
    "\n",
    "No overfitting, and an R2 score that's still a little tight. Optimization check :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_reg_train_score,best_reg_test_score, Reg_train_score, Reg_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a782838",
   "metadata": {},
   "source": [
    "Aucune plus value de GridSearch pour ce modèle \n",
    "No added value from GridSearch for this model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8f849",
   "metadata": {},
   "source": [
    "### 2.2.2 RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460a170",
   "metadata": {},
   "source": [
    "J'ai procédé de la sorte pour tout mes modèles, je vais désormais seulement commenter les résultats \n",
    "I've done this for all my models, and from now on I'll just comment on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Forest_model, Forest_train_score, Forest_test_score =evaluation(RandomForestRegressor, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7bb7e5",
   "metadata": {},
   "source": [
    "R2 score très bon, et pas d'overtfitting. Les temps de calculs sont longs pour mon ordinateur pour l'optimisation de la grille de paramètres. J'ai décidé de couper les paramètres en deux sets. J'ai calculé le set 1 seul, puis le set 2 avec les paramètres du set 1 calculés. Ce n'est peut-être pas la méthode optimale et les résultats changeraient peut-être\n",
    "\n",
    "R2 score very good, and no overtfitting. My computer is taking a long time to optimize the parameter grid. I decided to split the parameters into two sets. I calculated set 1 alone, then set 2 with the calculated set 1 parameters. This may not be the optimum method, and the results may change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_Forest = {    \n",
    "    \n",
    "    #Set 1  \n",
    "    'n_estimators': [50, 100, 200],  # Nombre d'arbres dans la forêt\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Nombre maximum de fonctionnalités considérées pour la scission\n",
    "    'max_depth': [None, 10, 20, 30],  # Profondeur maximale de chaque arbre \n",
    "    \n",
    "    #Set 2 \n",
    "    'min_samples_split': [2, 5, 10],  # Nombre minimum d'échantillons requis pour scinder un nœud interne\n",
    "    'min_samples_leaf': [1, 2, 4],  # Nombre minimum d'échantillons requis pour être une feuille\n",
    "    'bootstrap': [True, False]  # Méthode d'échantillonnage pour la construction d'arbres   \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_Forest = best_param(Forest_model, X_train, Y_train, param_grid_Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4cb89",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'bootstrap': False, 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "\n",
    "The best hyperparameters are : {'bootstrap': False, 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_Forest_model, best_Forest_train_score, best_Forest_test_score = evaluation(RandomForestRegressor, X_train, Y_train, X_test, Y_test, best_param_Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8830ef",
   "metadata": {},
   "source": [
    "R2 score très bon une nouvelle fois et pas d'overfitting\n",
    "\n",
    "R2 very good score once again and no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_Forest_train_score,best_Forest_test_score,Forest_train_score, Forest_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13b30b",
   "metadata": {},
   "source": [
    "RandomForest est un bon model, et bien optmisé par GridSearch. Cependant curieusement seul le train set est optmisé\n",
    "\n",
    "RandomForest is a good model, and well opted for by GridSearch. Curiously, however, only the train set is optmized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7599c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(best_Forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eeccf4",
   "metadata": {},
   "source": [
    "Le score reste le même sensiblement le même, le modèle est robuste.\n",
    "The score remains more or less the same, and the model is robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269dc70b",
   "metadata": {},
   "source": [
    "### 2.2.3 SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fb15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVR_model, SVR_train_score, SVR_test_score =evaluation(SVR, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3808219",
   "metadata": {},
   "source": [
    "R2 score correct, mais il y a de l'overfitting. La grille pourra peut-être fixer ce problème\n",
    "R2 correct score, but there's some overfitting. The grid may be able to fix this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8143a",
   "metadata": {},
   "source": [
    "Une nouvelle fois les temps de calculs sont longs. J'ai procédé de la même manière que 2.2.2 \n",
    "Once again, calculation times are long. I proceeded in the same way as 2.2.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SVR = {\n",
    "    \n",
    "    #Set 1  \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Type de noyau à utiliser dans le modèle SVM\n",
    "    'C': [0.1, 1, 10],  # Paramètre de régularisation, contrôle la pénalité pour les erreurs d'entraînement\n",
    "    \n",
    "    #Set 2 \n",
    "    'gamma': ['scale', 'auto', 0.1, 1],  # Paramètre du noyau (pour les noyaux RBF, poly et sigmoïde)\n",
    "    'epsilon': [0.1, 0.2, 0.5]  # Détermine la largeur de la marge autour de la valeur de régression attendue\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dddc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_SVR = best_param(SVR_model, X_train, Y_train, param_grid_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a816c1e",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'C': 10, 'epsilon': 0.2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "The best hyperparameters are: {'C': 10, 'epsilon': 0.2, 'gamma': 'scale', 'kernel': 'rbf'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_SVR_model, best_SVR_train_score, best_SVR_test_score = evaluation(SVR, X_train, Y_train, X_test, Y_test, best_param_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_SVR_train_score,best_SVR_test_score,SVR_train_score, SVR_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1caf52",
   "metadata": {},
   "source": [
    "Score amélioré, overfitting réduit mais toujours présent.\n",
    "Score improved, overfitting reduced but still present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(best_SVR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4b0cf",
   "metadata": {},
   "source": [
    "Le score reste le même sensiblement le même, le modèle est robuste.\n",
    "The score remains more or less the same, and the model is robust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de05d3c",
   "metadata": {},
   "source": [
    "### 2.2.4 AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABR_model, ABR_train_score, ABR_test_score =evaluation(AdaBoostRegressor, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d999af4",
   "metadata": {},
   "source": [
    "R2 score correct, et pas d'overfitting\n",
    "R2 correct score, no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ABR = {\n",
    "   'n_estimators': [50, 100, 200],  # Nombre d'estimateurs (régresseurs faibles) dans la chaîne\n",
    "   'learning_rate': [0.01, 0.1, 0.5, 1.0],  # Taux d'apprentissage, contrôle la contribution de chaque estimateur\n",
    "   'loss': ['linear', 'square', 'exponential'],  # Fonction de perte à optimiser lors de la mise à jour des poids\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62361629",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_ABR = best_param(ABR_model, X_train, Y_train, param_grid_ABR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bfd33",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 200}\n",
    "The best hyperparameters are: {'learning_rate': 0.1, 'loss': 'exponential', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ABR_model, best_ABR_train_score, best_ABR_test_score = evaluation(AdaBoostRegressor, X_train, Y_train, X_test, Y_test, best_param_ABR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_ABR_train_score,best_ABR_test_score,ABR_train_score, ABR_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43aa8f",
   "metadata": {},
   "source": [
    "Modèle correct dans son score, et amélioration legère par GridSearchCV\n",
    "Correct model score, slightly improved by GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bac8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(best_ABR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff16a4",
   "metadata": {},
   "source": [
    "Le score varie peu, le modèle est robuste\n",
    "The score varies little, the model is robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62730715",
   "metadata": {},
   "source": [
    "### 2.2.5 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a28604",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR_model, DTR_train_score, DTR_test_score =evaluation(DecisionTreeRegressor, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6490a90",
   "metadata": {},
   "source": [
    "Très bon R2 score et pas d'overfitting\n",
    "Very good R2 score and no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddababb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_DTR = {    \n",
    "   'max_depth': [None, 5, 10, 20],  # Profondeur maximale de l'arbre\n",
    "   'min_samples_split': [2, 5, 10],  # Nombre minimum d'échantillons requis pour scinder un nœud interne\n",
    "   'min_samples_leaf': [1, 2, 4],  # Nombre minimum d'échantillons requis pour être une feuille\n",
    "   'max_features': ['sqrt', 'log2'],  # Nombre maximum de fonctionnalités considérées pour la scission\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f325ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_DTR = best_param(DTR_model, X_train, Y_train, param_grid_DTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c02948",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
    "The best hyperparameters are: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_DTR_model, best_DTR_train_score, best_DTR_test_score = evaluation(DecisionTreeRegressor, X_train, Y_train, X_test, Y_test, best_param_DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_DTR_train_score,best_DTR_test_score,DTR_train_score, DTR_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea1e5d",
   "metadata": {},
   "source": [
    "Le modèle est très bon et fonctionne mieux avec les paramètres par défauts\n",
    "The model is very good and works best with the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(best_DTR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad5308",
   "metadata": {},
   "source": [
    "Le score ne change pas de manière significatif, le modèle est robuste\n",
    "Score does not change significantly, model is robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38631c1b",
   "metadata": {},
   "source": [
    "### 2.2.6 KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNR_model, KNR_train_score, KNR_test_score =evaluation(KNeighborsRegressor, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f56ae",
   "metadata": {},
   "source": [
    "Très bon R2 score et pas d'overfitting\n",
    "Very good R2 score and no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8537fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_KNR = {\n",
    "    'n_neighbors': [3, 5, 7, 9],  # Nombre de voisins à considérer\n",
    "    'weights': ['uniform', 'distance'],  # Poids donnés aux voisins (uniformes ou inverses de la distance)\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithme utilisé pour calculer les voisins\n",
    "    'leaf_size': [10, 20, 30],  # Taille de la feuille pour les arbres (utilisé avec ball_tree ou kd_tree)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c161d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_KNR = best_param(KNR_model, X_train, Y_train, param_grid_KNR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4251c05",
   "metadata": {},
   "source": [
    "Les meilleurs hyperparamètres sont : {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 3, 'weights': 'distance'}\n",
    "The best hyperparameters are: {'algorithm': 'auto', 'leaf_size': 10, 'n_neighbors': 3, 'weights': 'distance'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a55444",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_KNR_model, best_KNR_train_score, best_KNR_test_score = evaluation(KNeighborsRegressor, X_train, Y_train, X_test, Y_test, best_param_KNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49594f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Verification_opti(best_KNR_train_score,best_KNR_test_score,KNR_train_score, KNR_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c80e9e",
   "metadata": {},
   "source": [
    "Bon modèle et fonctionne mieux quand il est optimisé\n",
    "Good model and works best when optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a88909",
   "metadata": {},
   "outputs": [],
   "source": [
    "robustesse(best_KNR_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce385a",
   "metadata": {},
   "source": [
    "Le model est robuste car les scores ne changent peu.\n",
    "The model is robust because the scores change very little."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42522f4d",
   "metadata": {},
   "source": [
    "## 2.3 Résultats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9056919",
   "metadata": {},
   "source": [
    "Prédiction des données à l'aide des différents modèles\n",
    "Data prediction using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeba82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_Reg = Reg_model.predict(X_test)\n",
    "Y_pred_Forest = best_Forest_model.predict(X_test)\n",
    "Y_pred_SVR = best_SVR_model.predict(X_test)\n",
    "Y_pred_ABR = best_ABR_model.predict(X_test)\n",
    "Y_pred_DTR = DTR_model.predict(X_test)\n",
    "Y_pred_KNR = best_KNR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b804d719",
   "metadata": {},
   "source": [
    "Comparaison des histogrammes prédits par les modèles :\n",
    "\n",
    "Comparison of histograms predicted by the models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 8))\n",
    "fig.suptitle('Comparaison des prédictions des modèles')\n",
    "\n",
    "# Liste des prédictions et des labels correspondants\n",
    "predictions = [Y_pred_Reg, Y_pred_Forest, Y_pred_SVR, Y_pred_ABR, Y_pred_DTR, Y_pred_KNR]\n",
    "labels = ['Linear', 'RandomForest', 'SVR', 'AdaBoost', 'DecisionTree', 'KNeighbors']\n",
    "\n",
    "# Afficher les histogrammes normalisés des prédictions dans des sous-graphiques\n",
    "for pred, label, ax in zip(predictions, labels, axes.flatten()):\n",
    "    ax.hist(Y, bins=30, alpha=0.5, label='Y', density=True)\n",
    "    ax.hist(pred, bins=30, alpha=0.5, label=f'Y_pred_{label}', density=True)    \n",
    "    ax.set_title(f'Modèle {label}')\n",
    "    ax.set_xlabel('Valeurs')\n",
    "    ax.set_ylabel('Densité de probabilité')\n",
    "    ax.legend()\n",
    "\n",
    "# Ajuster la disposition des sous-graphiques\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2ddf7",
   "metadata": {},
   "source": [
    "On voit nettement que les modèles AdaBoost et Linear ne reproduisent pas fidèlement l'histogramme initial. Le modèle SVR ne repoduit pas très bien le centre et la queue droite. Concerant les trois dernièrs, bien qu'il y ait une surévaluation par endroits, les modèles semblent approprier pour prédire les données. Pour cela, je vais déterminer avec un score par la suite le meilleur\n",
    "\n",
    "We can clearly see that the AdaBoost and Linear models do not faithfully reproduce the original histogram.The SVR model does not reproduce the center and right tail very well. With regard to the last three, although there is an overestimation in places, the models seem to be suitable for predicting the data. To this end, I'm going to determine with a score the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47c1d7",
   "metadata": {},
   "source": [
    "Affichage des statistiques des prédites à celles des données originale: \n",
    "\n",
    "Display statistics from predicted to original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2297e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = {\n",
    "    'Y_pred_Reg': Reg_model.predict(X_test),\n",
    "    'Y_pred_Forest': best_Forest_model.predict(X_test),\n",
    "    'Y_pred_SVR': best_SVR_model.predict(X_test),\n",
    "    'Y_pred_ABR': best_ABR_model.predict(X_test),\n",
    "    'Y_pred_DTR': DTR_model.predict(X_test),\n",
    "    'Y_pred_KNR': best_KNR_model.predict(X_test)\n",
    "}\n",
    "\n",
    "# Créer le DataFrame avec les prédictions\n",
    "predictions_df = pd.DataFrame(model_predictions)\n",
    "\n",
    "# Obtenir les statistiques descriptives des prédictions\n",
    "predictions_stats = predictions_df.describe()\n",
    "\n",
    "# Créer le DataFrame de comparaison\n",
    "comparison_stats = pd.concat([df['Eat'].describe(), predictions_stats], axis=1)\n",
    "comparison_stats.columns = ['Y'] + list(model_predictions.keys())\n",
    "\n",
    "# Afficher le DataFrame de comparaison\n",
    "comparison_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fe7c3",
   "metadata": {},
   "source": [
    "Dans l'ensemble la moyenne, la déviation standard, le premier quartile, le deuxième quartile et le troisième quartile semblent correctement prédits. Le minimum et le maximum ne sont cependant pas correctement prédits par le modèle Linear Regression et et AdaBoost Regression, ce qui etait visible sur les histogramme\n",
    "\n",
    "Overall, the mean, standard deviation, first quartile, second quartile and third quartile appear to be correctly predicted. The minimum and maximum, however, are not correctly predicted by the Linear Regression and AdaBoost Regression models, as can be seen from the histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c45a08",
   "metadata": {},
   "source": [
    "Autre visualisation des données prédites, cette fois-ci, les erreurs absolues sont représentées :\n",
    "\n",
    "Another visualization of predicted data, this time showing absolute errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_stats = pd.DataFrame(index=['mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "\n",
    "for model_name, model_prediction in model_predictions.items():\n",
    "    # Calculer l'erreur absolue pour chaque statistique descriptive\n",
    "    error_stats[f'Absolute_Error_{model_name}'] = abs(predictions_stats[model_name] - df['Eat'].describe())*100\n",
    "\n",
    "# Afficher le DataFrame des erreurs absolues des statistiques descriptives\n",
    "error_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd708a",
   "metadata": {},
   "source": [
    "On constate que les modèles prédisent plus ou moins bien. C'est pourquoi je vais leur attribuer un score. Ligne par ligne, le modèle ayant l'erreur la plus faible obtient un score de 1 et ainsi de suite jusqu'à l'erreur la plus grande. Au final, le modèle avec le plus faible score, sera le modèle qui a fait les erreurs les plus faibles devant les autres.\n",
    "\n",
    "We can see that the models predict more or less well. That's why I'm going to give them a score. Line by line, the model with the lowest error gets a score of 1, and so on down to the highest error. In the end, the model with the lowest score will be the one with the smallest errors, ahead of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0665e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les scores à 0 dans un dictionnaire\n",
    "model_scores = {model: 0 for model in model_predictions.keys()}\n",
    "\n",
    "# Parcourir chaque ligne du DataFrame\n",
    "for index, row in error_stats.iterrows():\n",
    "    # Trier les colonnes par valeur\n",
    "    sorted_columns = row.sort_values().index\n",
    "    \n",
    "    # Attribuer des scores de 1 à 6 en fonction de la position des colonnes\n",
    "    assigned_positions = set()  # Garder une trace des positions déjà attribuées\n",
    "    for position, model_column in enumerate(sorted_columns, start=1):\n",
    "        # Extraire le nom du modèle à partir de la colonne\n",
    "        model_name = model_column.replace('Absolute_Error_', '')\n",
    "        \n",
    "        # Gérer l'égalité en ajoutant la position suivante non attribuée\n",
    "        while position in assigned_positions:\n",
    "            position += 1\n",
    "        \n",
    "        # Ajouter le score à la position du modèle dans le dictionnaire\n",
    "        model_scores[model_name] += position\n",
    "        assigned_positions.add(position)\n",
    "\n",
    "\n",
    "# Trier le dictionnaire par valeurs (scores) et afficher l'ordre croissant\n",
    "sorted_scores = sorted(model_scores.items(), key=lambda x: x[1])\n",
    "print(\"Scores attribués à chaque modèle :\")\n",
    "for model, score in sorted_scores:\n",
    "    print(f\"{model} : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a3aed",
   "metadata": {},
   "source": [
    "Ainsi sont donnés dans l'ordre le meilleur modèle au pire : KNeighborsRegressor, RandomForestRegressor, DecisionTreeRegressor, SVR, Linear Regressor, AdaBoostRegressor. AdaBoostRegressor n'était pas le modèle avec le pire score, mais est celui qui reproduit le moins bien les données statistiques attendues. Cela montre que un autre score serait peut-être plus adapté dans notre situation.\n",
    "\n",
    "In order of best to worst, the following models are given: KNeighborsRegressor, RandomForestRegressor, DecisionTreeRegressor, SVR, Linear Regressor, AdaBoostRegressor. AdaBoostRegressor was not the model with the worst score, but it is the one that reproduces the expected statistical data least well. This suggests that another score might be more appropriate in our situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
